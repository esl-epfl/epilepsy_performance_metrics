{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage of the Performance Metric library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations\n",
    "\n",
    "The library allows to compare two sets of annotations of a binary classification problem on a time series. In our application field this corresponds to labeling of epileptic seizures in an EEG recording.\n",
    "\n",
    "Annotations are stored an can be loaded in one of two representations :\n",
    "- Binary mask at the sampling frequency of labels (e.g. `11111100000111111111000000`)\n",
    "- List of (start, stop) tuples representing the different events. These evens are stored in seconds (e.g. `[(0, 6), (11, 20)]`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation objects contain a representation as a mask and as a list of events:\n",
      "[False  True  True False False False  True  True  True False]\n",
      "[(1.0, 3.0), (6.0, 9.0)]\n"
     ]
    }
   ],
   "source": [
    "from annotations import Annotation\n",
    "\n",
    "# Annotation objects can be instantiated from a binary mask\n",
    "\n",
    "fs = 1\n",
    "mask = [0,1,1,0,0,0,1,1,1,0]\n",
    "\n",
    "labels = Annotation(mask, fs)\n",
    "\n",
    "print('Annotation objects contain a representation as a mask and as a list of events:')\n",
    "print(labels.mask)\n",
    "print(labels.events)\n",
    "\n",
    "\n",
    "# The Annotation object can also be instantiated from a list of events\n",
    "fs = 1\n",
    "numSamples = 10  # In this case the duration of the recording in samples should be provided\n",
    "events = [(1, 3), (6, 9)]\n",
    "\n",
    "labels = Annotation(events, fs, numSamples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "The scoring module takes a reference annotation (ground-truth labels) and a hypothesis (e.g. output of an ML pipeline) and computes seizure detection performance metrics.\n",
    "\n",
    "The class implements two types of scoring algorithms :\n",
    "- Window based scoring : Computes detections and errors on a sample by sample basis at the sampling frequency of the labels\n",
    "- Event based scoring  : Computes detections and errors per event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Window scoring\n",
      "- Sensitivity : 0.50 \n",
      "- Precision   : 0.60 \n",
      "- F1-score    : 0.55 \n",
      "- FP/24h      : 172800.00 \n",
      "\n",
      "# Event scoring\n",
      "- Sensitivity : 0.50 \n",
      "- Precision   : 0.50 \n",
      "- F1-score    : 0.50 \n",
      "- FP/24h      : 86400.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scoring\n",
    "\n",
    "fs = 10\n",
    "ref = Annotation([1,1,1,0,0,0,1,1,1,0], fs)\n",
    "hyp = Annotation([0,1,1,0,1,1,0,0,1,0], fs)\n",
    "scores = scoring.WindowScoring(ref, hyp)\n",
    "\n",
    "\n",
    "print(\"# Window scoring\\n\" +\n",
    "      \"- Sensitivity : {:.2f} \\n\".format(scores.sensitivity) + \n",
    "      \"- Precision   : {:.2f} \\n\".format(scores.precision) + \n",
    "      \"- F1-score    : {:.2f} \\n\".format(scores.f1) + \n",
    "      \"- FP/24h      : {:.2f} \\n\".format(scores.fpRate))\n",
    "\n",
    "\n",
    "# Scores can also be computed per event\n",
    "param = scoring.EventScoring.Parameters(\n",
    "    toleranceStart=0,\n",
    "    toleranceEnd=0,\n",
    "    minOverlap=0.66,\n",
    "    maxEventDuration=5*60)\n",
    "scores = scoring.EventScoring(ref, hyp, param)\n",
    "\n",
    "print(\"# Event scoring\\n\" +\n",
    "      \"- Sensitivity : {:.2f} \\n\".format(scores.sensitivity) + \n",
    "      \"- Precision   : {:.2f} \\n\".format(scores.precision) + \n",
    "      \"- F1-score    : {:.2f} \\n\".format(scores.f1) + \n",
    "      \"- FP/24h      : {:.2f} \\n\".format(scores.fpRate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "performance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
